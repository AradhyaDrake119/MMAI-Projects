{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WwG5uxEpKaNL"
   },
   "source": [
    "# MMAI 894 - Exercise 2\n",
    "## Convolutional artificial neural network : Image classification\n",
    "The goal of this excercise is to build a convolutional neural network using the tensorflow/keras library. We will be using the MNIST dataset.\n",
    "Submission instructions:\n",
    "\n",
    "- You cannot edit this notebook directly. Save a copy to your drive, and make sure to identify yourself in the title using name and student number\n",
    "- Do not insert new cells before the final one (titled \"Further exploration\") \n",
    "- Verify that your notebook can _restart and run all_. \n",
    "- Select File -> Download as .py (important! not as ipynb)\n",
    "- Rename the file: `studentID_lastname_firstname_ex2.py`\n",
    "- The mark will be assessed on the implementation of the functions with #TODO\n",
    "- **Do not change anything outside the functions**  unless in the further exploration section\n",
    "- As you are encouraged to explore the network configuration, 20% of the mark is based on final accuracy achieving greater than 98.5% on the test set.\n",
    "- Note: You do not have to answer the questions in thie notebook as part of your submission. They are meant to guide you.\n",
    "\n",
    "- You should not need to use any additional libraries other than the ones listed below. You may want to import additional modules from those libraries, however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "o-DUt8ROKlvw"
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "# Add modules as needed\n",
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# For windows laptops add following 2 lines:\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "arrbzOo4LR9q"
   },
   "source": [
    "### Data preparation\n",
    "\n",
    "#### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "s4wT7dbPLTNZ"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # Import MNIST dataset from openml\n",
    "    dataset = fetch_openml('mnist_784', version=1, data_home=None)\n",
    "\n",
    "    # Data preparation\n",
    "    raw_X = dataset['data']\n",
    "    raw_Y = dataset['target']\n",
    "    return raw_X, raw_Y\n",
    "\n",
    "raw_X, raw_Y = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WRp1jQTrLc39"
   },
   "source": [
    "## Consider the following\n",
    "- Same as excercise 1\n",
    "- what shape should x be for a convolutional network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8mG0hdDRLZgD"
   },
   "outputs": [],
   "source": [
    "def clean_data(raw_X, raw_Y):\n",
    "    # Convert Y to integers\n",
    "    cleaned_Y = raw_Y.astype(int)\n",
    "\n",
    "    # Convert X to numpy array \n",
    "    cleaned_X = np.array(raw_X) / 255\n",
    "\n",
    "    # Reshape X \n",
    "    cleaned_X = cleaned_X.reshape(-1, 28, 28, 1)\n",
    "\n",
    "    # Shuffle X and Y in unison\n",
    "    indices = np.random.permutation(len(cleaned_X))\n",
    "    cleaned_X = cleaned_X[indices]\n",
    "    cleaned_Y = cleaned_Y[indices]\n",
    "\n",
    "    # QA check\n",
    "    assert cleaned_X.shape[0] == cleaned_Y.shape[0]\n",
    "\n",
    "    return cleaned_X, cleaned_Y\n",
    "\n",
    "\n",
    "\n",
    "cleaned_X, cleaned_Y = clean_data(raw_X, raw_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5OYgzj7NU_y"
   },
   "source": [
    "#### Data split\n",
    "\n",
    "- Split your data into a train set (50%), validation set (20%) and a test set (30%). You can use scikit-learn's train_test_split function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7h7HIVDNNYap"
   },
   "outputs": [],
   "source": [
    "def split_data(cleaned_X, cleaned_Y):\n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(cleaned_X, cleaned_Y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Split train set into train and validation sets\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2857, random_state=42)\n",
    "    \n",
    "    return X_val, X_test, X_train, Y_val, Y_test, Y_train\n",
    "\n",
    "\n",
    "X_val, X_test, X_train, Y_val, Y_test, Y_train = split_data(cleaned_X, cleaned_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mY_z08TdNada"
   },
   "source": [
    "### Model\n",
    "\n",
    "#### Neural network structure\n",
    "\n",
    "This time, the exact model architecture is left to you to explore.  \n",
    "Keep the number of parameters below 2,000,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "dKAx26EDN3Yk"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def compile_model(model):\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_model(model, X_train, Y_train, X_val, Y_val):\n",
    "    history = model.fit(X_train, Y_train, epochs=18,\n",
    "                        validation_data=(X_val, Y_val),verbose=1)\n",
    "    return model, history\n",
    "\n",
    "def eval_model(model, X_test, Y_test):\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, Y_test,verbose=0)\n",
    "    print('Test loss:', test_loss)\n",
    "    print('Test accuracy:', test_accuracy)\n",
    "    return test_loss, test_accuracy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Bg5E9ChPOt_l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n",
      "1094/1094 [==============================] - 26s 23ms/step - loss: 0.1893 - accuracy: 0.9440 - val_loss: 0.0881 - val_accuracy: 0.9729\n",
      "Epoch 2/18\n",
      "1094/1094 [==============================] - 24s 22ms/step - loss: 0.0601 - accuracy: 0.9812 - val_loss: 0.0759 - val_accuracy: 0.9779\n",
      "Epoch 3/18\n",
      "1094/1094 [==============================] - 24s 22ms/step - loss: 0.0369 - accuracy: 0.9882 - val_loss: 0.0771 - val_accuracy: 0.9770\n",
      "Epoch 4/18\n",
      "1094/1094 [==============================] - 25s 22ms/step - loss: 0.0247 - accuracy: 0.9920 - val_loss: 0.0721 - val_accuracy: 0.9791\n",
      "Epoch 5/18\n",
      "1094/1094 [==============================] - 24s 22ms/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 0.0740 - val_accuracy: 0.9796\n",
      "Epoch 6/18\n",
      "1094/1094 [==============================] - 25s 22ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.0668 - val_accuracy: 0.9823\n",
      "Epoch 7/18\n",
      "1094/1094 [==============================] - 24s 22ms/step - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.0718 - val_accuracy: 0.9826\n",
      "Epoch 8/18\n",
      "1094/1094 [==============================] - 25s 22ms/step - loss: 0.0079 - accuracy: 0.9971 - val_loss: 0.0718 - val_accuracy: 0.9831\n",
      "Epoch 9/18\n",
      "1094/1094 [==============================] - 24s 22ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.0853 - val_accuracy: 0.9807\n",
      "Epoch 10/18\n",
      "1094/1094 [==============================] - 24s 22ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.0942 - val_accuracy: 0.9817\n",
      "Epoch 11/18\n",
      "1094/1094 [==============================] - 24s 22ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.0903 - val_accuracy: 0.9818\n",
      "Epoch 12/18\n",
      "1094/1094 [==============================] - 24s 22ms/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.0833 - val_accuracy: 0.9836\n",
      "Epoch 13/18\n",
      "1094/1094 [==============================] - 24s 22ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0879 - val_accuracy: 0.9837\n",
      "Epoch 14/18\n",
      "1094/1094 [==============================] - 24s 22ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0836 - val_accuracy: 0.9836\n",
      "Epoch 15/18\n",
      "1094/1094 [==============================] - 25s 22ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.1051 - val_accuracy: 0.9811\n",
      "Epoch 16/18\n",
      "1094/1094 [==============================] - 24s 22ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0882 - val_accuracy: 0.9840\n",
      "Epoch 17/18\n",
      "1094/1094 [==============================] - 25s 22ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.1087 - val_accuracy: 0.9809\n",
      "Epoch 18/18\n",
      "1094/1094 [==============================] - 24s 22ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.1010 - val_accuracy: 0.9835\n",
      "Test loss: 0.09119474142789841\n",
      "Test accuracy: 0.9857142567634583\n"
     ]
    }
   ],
   "source": [
    "## You may use this space (and add additional cells for exploration)\n",
    "\n",
    "model = build_model()\n",
    "model = compile_model(model)\n",
    "model, history = train_model(model, X_train, Y_train, X_val, Y_val)\n",
    "test_loss, test_accuracy = eval_model(model, X_test, Y_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
